{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjrTxiwWW59/DHz0NLXVay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunusemravci/ML-Assignments/blob/master/A4_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4snAlM3bbRSk",
        "outputId": "a42c3c8b-d610-4033-cdce-7ed8fe30735c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "4FJVACgEbbPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Data"
      ],
      "metadata": {
        "id": "2reh1eW4bf-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of column names\n",
        "column_names = [\n",
        "    'family', 'product-type', 'steel', 'carbon', 'hardness','temper_rolling', 'condition', 'formability', 'strength',\n",
        "    'non-ageing', 'surface-finish', 'surface-quality', 'enamelability', 'bc', 'bf',\n",
        "    'bt', 'bw/me', 'bl', 'm', 'chrom', 'phos', 'cbond', 'marvi', 'exptl', 'ferro',\n",
        "    'corr', 'blue/bright/varn/clean', 'lustre', 'jurofm', 's', 'p', 'shape', 'thick', 'width', 'len', 'oil',\n",
        "    'bore', 'packing', 'classes'\n",
        "]\n",
        "\n",
        "data_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/HW4/annealing/anneal.data\", delimiter=',', header=None)\n",
        "data_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/HW4/annealing/anneal.test\", delimiter=',', header=None)\n",
        "\n",
        "data_train.columns = column_names\n",
        "data_test.columns = column_names"
      ],
      "metadata": {
        "id": "XXgLt7yibfjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing Step"
      ],
      "metadata": {
        "id": "0xIRjxbTgi2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    # Extract the 'classes' column before preprocessing\n",
        "    classes_col = df['classes']\n",
        "\n",
        "    # Drop the 'classes' column from the dataframe\n",
        "    df = df.drop(columns='classes')\n",
        "\n",
        "    # Replace '?' with NaN using numpy's nan\n",
        "    df = df.replace('?', np.nan)\n",
        "\n",
        "    # Fill numerical columns with mean\n",
        "    for col in df.select_dtypes(include='number').columns:\n",
        "        df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "    # Fill categorical columns with the most frequent value\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = df[col].fillna(df[col].mode().iloc[0])\n",
        "\n",
        "    # Convert categorical data\n",
        "    df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "    # Append back the 'classes' column\n",
        "    df['classes'] = classes_col\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "lK3v08M03-h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Apply Prepocesses Method for both train and test data"
      ],
      "metadata": {
        "id": "bPiDgEhtgniZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the data\n",
        "train_df = preprocess_data(data_train)\n",
        "test_df = preprocess_data(data_test)"
      ],
      "metadata": {
        "id": "sM74rG8Ukv4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Column Matching\n",
        "Preprocessing step makes conflict on test data. In this case, columns of test dataset should be matched with training dataset"
      ],
      "metadata": {
        "id": "GdcpOvRPgxLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure columns in test_df match those in train_df\n",
        "for col in train_df.columns:\n",
        "    if col not in test_df.columns:\n",
        "        test_df[col] = 0\n",
        "\n",
        "# Now, reorder the columns of test_df to match train_df\n",
        "test_df = test_df[train_df.columns]\n"
      ],
      "metadata": {
        "id": "KYCce72R7MXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drop NaN columns\n",
        "All colums listed below include NaN which is decreasing the model accuracy. So that, these colums are removed from test and train datasets"
      ],
      "metadata": {
        "id": "s_avLHeYhKOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['m', 'marvi', 'corr', 'jurofm', 's', 'p']\n",
        "train_df.drop(columns=columns_to_drop, inplace=True)\n",
        "test_df.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "kyyxA6bPB6ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalization with Standard Scaler"
      ],
      "metadata": {
        "id": "zAnH2EZ2hjDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(train_df.drop(columns=['classes']))\n",
        "y_train = train_df['classes']\n",
        "\n",
        "X_test = scaler.transform(test_df.drop(columns=['classes'])) # Use the same scaler fitted on training data\n",
        "y_test = test_df['classes']\n"
      ],
      "metadata": {
        "id": "-UIIEYc43El0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mapping for classes"
      ],
      "metadata": {
        "id": "EKLdXDIWhqh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping\n",
        "class_mapping = {label: idx for idx, label in enumerate(y_train.unique())}\n",
        "print(class_mapping)  # To see the created mapping\n",
        "\n",
        "y_train = y_train.map(class_mapping)\n",
        "y_test = y_test.map(class_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5UTfe9l8JEM",
        "outputId": "0737ba66-756a-4426-9e01-3a65615e33a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'3': 0, 'U': 1, '1': 2, '5': 3, '2': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Creation"
      ],
      "metadata": {
        "id": "doEX8kuyfeVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(y_train.nunique(), activation='softmax')\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6cAbrpKcErx",
        "outputId": "f344079c-3c32-4d81-ada8-d92a0eba25c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 11ms/step - loss: 0.8005 - accuracy: 0.7241 - val_loss: 0.4214 - val_accuracy: 0.8625\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8260 - val_loss: 0.3271 - val_accuracy: 0.8687\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8605 - val_loss: 0.2800 - val_accuracy: 0.8875\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.8809 - val_loss: 0.2773 - val_accuracy: 0.8750\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.8856 - val_loss: 0.2525 - val_accuracy: 0.9000\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.8950 - val_loss: 0.3228 - val_accuracy: 0.8500\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.8981 - val_loss: 0.2353 - val_accuracy: 0.9187\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2170 - accuracy: 0.8887 - val_loss: 0.2218 - val_accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9044 - val_loss: 0.2514 - val_accuracy: 0.8750\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9075 - val_loss: 0.2562 - val_accuracy: 0.9125\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.8997 - val_loss: 0.2599 - val_accuracy: 0.8562\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9028 - val_loss: 0.2590 - val_accuracy: 0.8625\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.9232 - val_loss: 0.2353 - val_accuracy: 0.9250\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9122 - val_loss: 0.2896 - val_accuracy: 0.8750\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9216 - val_loss: 0.2493 - val_accuracy: 0.8750\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9028 - val_loss: 0.3382 - val_accuracy: 0.8438\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9122 - val_loss: 0.1667 - val_accuracy: 0.9500\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1594 - accuracy: 0.9216 - val_loss: 0.2659 - val_accuracy: 0.8562\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9169 - val_loss: 0.2244 - val_accuracy: 0.9312\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9044 - val_loss: 0.2347 - val_accuracy: 0.8562\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9201 - val_loss: 0.1914 - val_accuracy: 0.9438\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9248 - val_loss: 0.2503 - val_accuracy: 0.9125\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9263 - val_loss: 0.2612 - val_accuracy: 0.8687\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1577 - accuracy: 0.9185 - val_loss: 0.2798 - val_accuracy: 0.8562\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9232 - val_loss: 0.2255 - val_accuracy: 0.8687\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9357 - val_loss: 0.2348 - val_accuracy: 0.9000\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9326 - val_loss: 0.2207 - val_accuracy: 0.8875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Print Loss and Accuracy"
      ],
      "metadata": {
        "id": "zy8NyDqah8ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mxKKT0Eh79i",
        "outputId": "c739193f-5976-49a8-9b0a-fc58f7530195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.3409\n",
            "Test Accuracy: 0.7800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Print Classification Report"
      ],
      "metadata": {
        "id": "Wg3LwVLkoVTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predicted probabilities to class labels\n",
        "\n",
        "print(classification_report(y_test, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynwxMECenQXS",
        "outputId": "002d72db-2a10-48bd-92d6-35e86532f13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.88        76\n",
            "           1       0.83      0.83      0.83         6\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.41      0.46      0.43       100\n",
            "weighted avg       0.66      0.80      0.72       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Print Confusion Matrix"
      ],
      "metadata": {
        "id": "apROUr4FoZ-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U77QVty8odcq",
        "outputId": "41b25349-8658-4058-ddd9-3ec12e0ae3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[75  1  0  0]\n",
            " [ 1  5  0  0]\n",
            " [ 7  0  0  0]\n",
            " [11  0  0  0]]\n"
          ]
        }
      ]
    }
  ]
}